# Ultralytics YOLO ğŸš€, AGPL-3.0 license

from pathlib import Path, PosixPath
import os

import numpy as np
import torch

from ultralytics.models.yolo.detect import DetectionValidator
from ultralytics.utils import LOGGER, ops
from ultralytics.utils.metrics import DetMetrics, box_iou, ReIDMetrics
from ultralytics.utils.torch_utils import smart_inference_mode
from ultralytics.utils.loss import StateMetrics #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡


class JDEValidator(DetectionValidator):
    """
    A class extending the DetectionValidator class for validation based on a joint detection and embedding model.

    Example:
        ```python
        from ultralytics.models.yolo.jde import JDEValidator

        args = dict(model="yolov8n-jde.pt", data="coco8-seg.yaml")
        validator = JDEValidator(args=args)
        validator()
        ```
    """

    def __init__(self, dataloader=None, save_dir=None, pbar=None, args=None, _callbacks=None):
        """Initialize SegmentationValidator and set task to 'segment', metrics to SegmentMetrics."""
        # ========== åœ¨è°ƒç”¨super()ä¹‹å‰æå–è‡ªå®šä¹‰å‚æ•° ==========
        # ä»argsä¸­æå–è‡ªå®šä¹‰å‚æ•°ï¼ˆå¦‚æœargsæ˜¯å­—å…¸ï¼‰
        if args is not None and isinstance(args, dict):
            # æå–è‡ªå®šä¹‰å‚æ•°
            self._model_name = args.pop('model_name', None)
            self._save_excel = args.pop('save_excel', False)
            self._excel_save_dir = args.pop('excel_save_dir', None)
            self._excel_name = args.pop('excel_name', 'result_all.xlsx')
            self._save_tag_to_txt = args.pop('save_tag_to_txt', False)
        else:
            # å¦‚æœargsä¸æ˜¯å­—å…¸æˆ–ä¸ºNoneï¼Œè®¾ç½®é»˜è®¤å€¼
            self._model_name = None
            self._save_excel = False
            self._excel_save_dir = None
            self._excel_name = 'result_all.xlsx'
            self._save_tag_to_txt = False
        
        # ç°åœ¨è°ƒç”¨super().__init__()ï¼Œæ­¤æ—¶argsä¸­å·²ç»ä¸åŒ…å«è‡ªå®šä¹‰å‚æ•°äº†
        super().__init__(dataloader, save_dir, pbar, args, _callbacks)
        self.plot_masks = None
        self.process = None
        #ï¿¥#self.args.task = "jde"  # ç¡®ä¿taskè®¾ç½®ä¸ºjdeï¼Œä»¥æ”¯æŒ6åˆ—æ ‡ç­¾æ ¼å¼
        self.metrics = DetMetrics(save_dir=self.save_dir, on_plot=self.on_plot)
        self.reid_metrics = ReIDMetrics()
        #model.person_states = data.get("person_states", {})
        
        # æ·»åŠ çŠ¶æ€é¢„æµ‹æŒ‡æ ‡ #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        #self.state_metrics = StateMetrics(num_states=166) #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®model #æ ¹æ®å®é™…çŠ¶æ€æ•°é‡è®¾ç½® #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        self.state_metrics = None #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢
        self._num_states_hint = getattr(self.args, "state_classes", None)  # #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢ å¯é€‰ï¼šä» args æç¤º
        # å­˜å‚¨çŠ¶æ€é¢„æµ‹æ•°æ®ç”¨äºæ‰¹å¤„ç†è¯„ä¼°
        self.all_pred_states = [] #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        self.all_target_states = [] #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        self.state_iou = 0.5  # é»˜è®¤0.5ï¼Œ0.75ç­‰
        
        # æ·»åŠ çŠ¶æ€æ£€æµ‹æŒ‡æ ‡ï¼ˆå¤ç”¨æ£€æµ‹æŒ‡æ ‡è®¡ç®—ï¼Œä½¿ç”¨ç›¸åŒçš„IoUé˜ˆå€¼å’Œç½®ä¿¡åº¦é˜ˆå€¼ï¼‰
        self.state_det_metrics = DetMetrics(save_dir=self.save_dir, on_plot=self.on_plot)
        # å­˜å‚¨çŠ¶æ€æ£€æµ‹çš„ç»Ÿè®¡æ•°æ®ï¼ˆç±»ä¼¼self.statsï¼‰
        self.state_det_stats = {
            "conf": [],
            "pred_cls": [],
            "tp": [],
            "target_cls": [],
            "target_img": [],
        }

    @smart_inference_mode()
    def __call__(self, trainer=None, model=None):
        """Performs validation on the model and sets the epoch and best attributes."""
        if trainer is None and model is not None : #ï¿¥#è¯„ä¼°é˜¶æ®µç”¨
            self.model_path = model if (isinstance(model, str) or isinstance(model, PosixPath)) else model.pt_path
            if hasattr(model, 'model') and hasattr(model.model[-1], 'state_classes'):
                self.model = model #$#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        elif trainer is not None: #$#è®­ç»ƒéªŒè¯é˜¶æ®µç”¨
            self.epoch = trainer.epoch + 1
            self.best = trainer.best
            self.trainer = trainer #ï¿¥#
            if model is None and hasattr(trainer, 'model'): #ï¿¥#
                self.model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model
                #self.model = trainer.model.module #ï¿¥#
            elif model is not None:
                self.model_path = model if (isinstance(model, str) or isinstance(model, PosixPath)) else model.pt_path
                self.model = model #$#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡        
        
        # ç¡®ä¿åœ¨è¿™é‡Œå®Œæˆ state_metrics çš„åˆå§‹åŒ– #$$$$$$$$$$$$$#  #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢
        self._ensure_state_metrics_initialized()#$$$$$$$$$$$$$# #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢

        stats = super().__call__(trainer, model)
        return stats
    def _ensure_state_metrics_initialized(self): #$$$$$$$$$$$$$# #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢
        if self.state_metrics is not None: #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢
            return  # å·²ç»åˆå§‹åŒ–è¿‡ #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢

        # 1) ä¼˜å…ˆä» args é‡Œæ‹¿ï¼ˆå¯é€‰ï¼Œè‹¥ä½ åœ¨å¤–éƒ¨é…ç½®è¿‡ï¼‰
        num_states = self._num_states_hint #&#åˆå§‹åŒ–ä¸èƒ½è®¿é—®modelæ›¿æ¢
        
        # 3) ä»æ¨¡å‹æ£€æµ‹å¤´è¯»å–state_classes
        if num_states is None and self.model is not None:
            head = getattr(self.model, "model", None)  # å¯èƒ½æ˜¯ nn.Sequential/ModuleList/è‡ªå®šä¹‰å®¹å™¨
            last = None
            if head is not None:
                # å¸¸è§ä¸¤ç§ç»“æ„ï¼šlist-like æˆ–å†åµŒå¥—ä¸€å±‚ .model
                if hasattr(head, "__getitem__"):
                    last = head[-1]
                else:
                    inner = getattr(head, "model", None)
                    if inner is not None and hasattr(inner, "__getitem__"):
                        last = inner[-1]
            if last is not None:
                num_states = getattr(last, "state_classes", None)

        # 4) å¦‚æœè¿˜æ²¡æœ‰æ‹¿åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼è€Œä¸æ˜¯æŠ¥é”™
        if num_states is None:
            print("è­¦å‘Šï¼šæ— æ³•è·å–state_classesï¼Œä½¿ç”¨é»˜è®¤å€¼166")
            num_states = 166  # ä½¿ç”¨é»˜è®¤å€¼ï¼Œé¿å…æŠ¥é”™

        self.state_metrics = StateMetrics(num_states=int(num_states))
    def _prepare_batch(self, si, batch):
        """Prepares a batch of images and annotations for validation."""
        idx = batch["batch_idx"] == si
        cls = batch["cls"][idx].squeeze(-1)
        tags = batch["tags"][idx].squeeze(-1)
        bbox = batch["bboxes"][idx]
        ori_shape = batch["ori_shape"][si]
        imgsz = batch["img"].shape[2:]
        if len(cls):
            bbox = ops.xywh2xyxy(bbox) * torch.tensor(imgsz, device=self.device)[[1, 0, 1, 0]]  # target boxes
            ops.scale_boxes(imgsz, bbox, ori_shape)  # native-space labels
        return {"cls": cls, "bbox": bbox, "ori_shape": ori_shape, "imgsz": imgsz, "tags": tags}

    def _prepare_pred(self, pred, pbatch):
        """Prepares a batch of images and annotations for validation."""
        predn = pred.clone()
        ops.scale_boxes(pbatch["imgsz"], predn[:, :4], pbatch["ori_shape"])  # native-space pred
        return predn

    def update_metrics(self, preds, batch):
        """Metrics."""
        batch_matched_tags = []
        
        # æ¸…ç©ºå½“å‰æ‰¹æ¬¡çš„çŠ¶æ€æ•°æ®
        self.current_batch_pred_states = [] #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        self.current_batch_target_states = [] #$#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        
        for si, pred in enumerate(preds):
            self.seen += 1
            npr = len(pred)
            stat = dict(
                conf=torch.zeros(0, device=self.device),
                pred_cls=torch.zeros(0, device=self.device),
                tp=torch.zeros(npr, self.niou, dtype=torch.bool, device=self.device),
            )
            matched_tags = torch.zeros(npr, dtype=torch.int, device=self.device)    # Initialize matched tags tensor
            pbatch = self._prepare_batch(si, batch)
            cls, bbox, tags = pbatch.pop("cls"), pbatch.pop("bbox"), pbatch.pop("tags")
            nl = len(cls)
            stat["target_cls"] = cls
            stat["target_img"] = cls.unique()
            if npr == 0:
                if nl:
                    for k in self.stats.keys():
                        self.stats[k].append(stat[k])
                    if self.args.plots:
                        self.confusion_matrix.process_batch(detections=None, gt_bboxes=bbox, gt_cls=cls)
                batch_matched_tags.append(matched_tags)#%ï¿¥ï¿¥%ï¿¥# æ·»åŠ ç©ºçš„matched_tagsï¼Œç¡®ä¿åˆ—è¡¨é•¿åº¦åŒ¹é…
                continue

            # Predictions
            if self.args.single_cls:
                pred[:, 5] = 0
            predn = self._prepare_pred(pred, pbatch)
            stat["conf"] = predn[:, 4]
            stat["pred_cls"] = predn[:, 5]
            """#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            # 1) å–çŠ¶æ€åˆ†æ”¯çš„æ¦‚ç‡ï¼Œç”Ÿæˆâ€œçŠ¶æ€=6ç±»æ£€æµ‹â€çš„ conf ä¸ cls
            embed_dim = self.model.model[-1].embed_dim #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            state_classes = self.model.model[-1].state_classes
            state_probs = pred[:, 6 + embed_dim : 6 + embed_dim + state_classes]          # (N, 6)
            state_conf, state_cls = state_probs.max(1, keepdim=True)   
        
            # 2) æ„é€ â€œçŠ¶æ€æ£€æµ‹â€çš„é¢„æµ‹çŸ©é˜µï¼š[x1,y1,x2,y2, conf_state, cls_state]
            pred_state_det = torch.cat([predn[:, :4], state_conf, state_cls.float()], dim=1)
            print(pred_state_det)

            # 3) ç”¨â€œçŠ¶æ€idâ€ä½œä¸ºGTç±»åˆ«ï¼ˆtagsæ˜¯1-basedï¼Œæ”¹æˆ0-basedï¼‰
            # æ„é€  GT çŠ¶æ€ç±»åˆ«ï¼Œä¿è¯æ˜¯ä¸€ç»´ (M,)ï¼›æ—  GT æ—¶è¿”å› shape=(0,) çš„ç©ºå¼ é‡
            if tags is not None and tags.numel() > 0:
                gt_state_cls = (tags-1).to(dtype=torch.long, device=pred.device).view(-1)  # (M,)
            else:
                gt_state_cls = torch.zeros(0, dtype=torch.long, device=pred.device)          # (0,)

            # åŒæ­¥æ„é€ å ä½çš„ gt_tagsï¼ˆä¸€ç»´ï¼‰ï¼Œmatch_predictions é‡Œä¼šç”¨åˆ°ä½†è¿™é‡Œä¸å…³å¿ƒå†…å®¹
            gt_dummy_tags = torch.zeros_like(gt_state_cls, dtype=torch.long, device=pred.device)  # (M,)

            # å†è°ƒç”¨åŒ¹é…ä¸ç»Ÿè®¡
            if pred_state_det.numel() > 0 or gt_state_cls.numel() > 0:
                stat["tp"], matched_tags = self._process_batch(pred_state_det, bbox, gt_state_cls, gt_dummy_tags)
            else:
                # ä¸¤è€…çš†ç©ºæ—¶ï¼ŒæŒ‰ç©ºç»Ÿè®¡å¤„ç†
                stat["tp"] = torch.zeros(0, self.niou, dtype=torch.bool, device=self.device)
                matched_tags = torch.zeros(0, dtype=torch.long, device=self.device)"""
 #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            # Evaluate #$#$#$#$ 
            if nl:
                stat["tp"], matched_tags = self._process_batch(predn, bbox, cls, tags)  
                if self.args.plots:
                    self.confusion_matrix.process_batch(predn, bbox, cls)
            for k in self.stats.keys():
                self.stats[k].append(stat[k])
            batch_matched_tags.append(matched_tags)

            # ========== çŠ¶æ€æ£€æµ‹æŒ‡æ ‡è®¡ç®—ï¼ˆå¤ç”¨æ£€æµ‹æŒ‡æ ‡ä»£ç ï¼Œå®Œå…¨æ›¿æ¢ç±»åˆ«å’Œç½®ä¿¡åº¦ï¼‰==========
            if hasattr(self, "state_det_stats") and hasattr(self.model.model[-1], "state_classes") and self.model.model[-1].state_classes is not None:
                embed_dim = self.model.model[-1].embed_dim
                state_classes = self.model.model[-1].state_classes
                
                # æå–çŠ¶æ€é¢„æµ‹æ¦‚ç‡ï¼ˆä»NMSå‰çš„predä¸­æå–ï¼Œç„¶ååŒ¹é…åˆ°prednï¼‰
                if pred.shape[1] > 6 + embed_dim and len(predn) > 0:
                    # ä»predä¸­æå–çŠ¶æ€é¢„æµ‹
                    state_probs_raw = pred[:, 6 + embed_dim:6 + embed_dim + state_classes]  # (N_pred, state_classes)
                    
                    # å¯¹çŠ¶æ€æ¦‚ç‡è¿›è¡Œsoftmax
                    state_probs_raw = torch.softmax(state_probs_raw, dim=1)
                    
                    # æ‰¾åˆ°prednä¸­æ¯ä¸ªé¢„æµ‹æ¡†å¯¹åº”çš„predä¸­çš„ç´¢å¼•ï¼ˆé€šè¿‡bbox IoUåŒ¹é…ï¼‰
                    if len(pred) > 0:
                        # predçš„bboxï¼ˆNMSå‰ï¼‰
                        pred_bboxes = pred[:, :4]  # (N_pred, 4)
                        # prednçš„bboxï¼ˆNMSåï¼‰
                        predn_bboxes = predn[:, :4]  # (N_predn, 4)
                        
                        # è®¡ç®—IoUçŸ©é˜µ
                        iou_matrix = box_iou(predn_bboxes, pred_bboxes)  # (N_predn, N_pred)
                        
                        # ä¸ºæ¯ä¸ªprednæ‰¾åˆ°æœ€åŒ¹é…çš„predç´¢å¼•
                        matched_indices = iou_matrix.argmax(dim=1)  # (N_predn,)
                        
                        # ä»åŒ¹é…çš„predä¸­æå–çŠ¶æ€é¢„æµ‹
                        state_probs = state_probs_raw[matched_indices]  # (N_predn, state_classes)
                        
                        # 1) ä½¿ç”¨çŠ¶æ€é¢„æµ‹çš„æœ€å¤§æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
                        state_conf_raw, state_cls = state_probs.max(1, keepdim=True)  # (N_predn, 1), (N_predn, 1)
                        #state_conf = state_conf_raw.squeeze(1)
                        # 2) ä½¿ç”¨æ£€æµ‹æ¡†ç½®ä¿¡åº¦ä½œä¸ºç½®ä¿¡åº¦ï¼ˆå› ä¸ºæ£€æµ‹æ¡†å·²ç»é€šè¿‡äº†NMSå’Œç½®ä¿¡åº¦é˜ˆå€¼ï¼‰
                        # è¿™æ ·å¯ä»¥ç¡®ä¿çŠ¶æ€æ£€æµ‹æŒ‡æ ‡ä¸ä¼šå› ä¸ºçŠ¶æ€ç½®ä¿¡åº¦è¿‡ä½è€Œè¢«è¿‡æ»¤
                        det_conf = predn[:, 4]  # æ£€æµ‹æ¡†çš„åŸå§‹ç½®ä¿¡åº¦
                        state_conf = det_conf
                        
                        
                        # 2) æ„é€ "çŠ¶æ€æ£€æµ‹"çš„é¢„æµ‹çŸ©é˜µï¼šä½¿ç”¨prednçš„bboxï¼Œæ›¿æ¢confå’Œclsä¸ºçŠ¶æ€ç›¸å…³çš„
                        pred_state_det = predn.clone()  # å¤åˆ¶prednï¼ˆåŒ…å«bboxã€confã€clsï¼‰
                        pred_state_det[:, 4] = state_conf  #.squeeze(1) æ›¿æ¢ç½®ä¿¡åº¦ä¸ºçŠ¶æ€ç½®ä¿¡åº¦
                        pred_state_det[:, 5] = state_cls.squeeze(1).float()  # æ›¿æ¢ç±»åˆ«ä¸ºçŠ¶æ€ç±»åˆ«
                    else:
                        # predä¸ºç©ºï¼Œä½†prednä¸ä¸ºç©ºï¼Œä½¿ç”¨prednçš„åŸå§‹confå’Œclsï¼ˆè™½ç„¶ä¸å‡†ç¡®ï¼Œä½†ä¿è¯ä»£ç ä¸æŠ¥é”™ï¼‰
                        pred_state_det = predn.clone()
                    
                    # 3) ç”¨"çŠ¶æ€id"ä½œä¸ºGTç±»åˆ«ï¼ˆtagsæ˜¯0-basedï¼Œ0-5å¯¹åº”6ä¸ªçŠ¶æ€ï¼‰
                    if tags is not None and tags.numel() > 0:
                        # ç¡®ä¿tagsæ˜¯0-based
                        gt_state_cls = tags.to(dtype=torch.long, device=pred.device).view(-1)  # (M,)
                        # æ£€æŸ¥èŒƒå›´ï¼šåº”è¯¥åœ¨0åˆ°state_classes-1ä¹‹é—´
                        gt_state_cls = gt_state_cls.clamp_(min=0, max=state_classes-1)
                    else:
                        gt_state_cls = torch.zeros(0, dtype=torch.long, device=pred.device)
                    
                    # 4) æ„é€ å ä½çš„gt_tagsï¼ˆmatch_predictionséœ€è¦ï¼Œä½†è¿™é‡Œä¸å…³å¿ƒå†…å®¹ï¼‰
                    gt_dummy_tags = torch.zeros_like(gt_state_cls, dtype=torch.long, device=pred.device)
                    
                    # 5) è®¡ç®—çŠ¶æ€æ£€æµ‹çš„TPçŸ©é˜µï¼ˆå¤ç”¨_process_batchï¼Œä½¿ç”¨ç›¸åŒçš„IoUé˜ˆå€¼ï¼‰
                    if pred_state_det.numel() > 0 and len(gt_state_cls) > 0:
                        # ä¸´æ—¶ä¿å­˜åŸå§‹nc
                        original_nc = self.nc
                        # ä¸´æ—¶è®¾ç½®ncä¸ºçŠ¶æ€ç±»åˆ«æ•°
                        self.nc = state_classes
                        
                        state_stat = dict(
                            conf=torch.zeros(0, device=self.device),
                            pred_cls=torch.zeros(0, device=self.device),
                            tp=torch.zeros(len(pred_state_det), self.niou, dtype=torch.bool, device=self.device),
                        )
                        state_stat["target_cls"] = gt_state_cls
                        state_stat["target_img"] = gt_state_cls.unique()
                        
                        # ä½¿ç”¨_process_batchè®¡ç®—çŠ¶æ€æ£€æµ‹çš„TPï¼ˆä½¿ç”¨ç›¸åŒçš„IoUé˜ˆå€¼ï¼‰
                        state_stat["tp"], _ = self._process_batch(pred_state_det, bbox, gt_state_cls, gt_dummy_tags)
                        # ä½¿ç”¨ä¸“é—¨çš„çŠ¶æ€æ£€æµ‹åŒ¹é…å‡½æ•°ï¼šå…ˆåŒ¹é…æ¡†ï¼ˆåŸºäºIoUï¼‰ï¼Œå†åˆ¤æ–­çŠ¶æ€ç±»åˆ«æ˜¯å¦æ­£ç¡®
                        # iou = box_iou(bbox, pred_state_det[:, :4])  # (M, N)ï¼ŒMæ˜¯GTæ•°é‡ï¼ŒNæ˜¯é¢„æµ‹æ•°é‡
                        # state_stat["tp"] = self.match_predictions_for_state_detection(
                        #     pred_state_det[:, 5].long(),  # é¢„æµ‹çš„çŠ¶æ€ç±»åˆ«
                        #     gt_state_cls,  # çœŸå®çš„çŠ¶æ€ç±»åˆ«
                        #     iou  # IoUçŸ©é˜µ
                        # )
                        state_stat["conf"] = pred_state_det[:, 4]  # çŠ¶æ€ç½®ä¿¡åº¦
                        state_stat["pred_cls"] = pred_state_det[:, 5].long()  # çŠ¶æ€ç±»åˆ«
                        
                        # æ¢å¤åŸå§‹nc
                        self.nc = original_nc
                        
                        # ä¿å­˜çŠ¶æ€æ£€æµ‹ç»Ÿè®¡æ•°æ®
                        for k in self.state_det_stats.keys():
                            self.state_det_stats[k].append(state_stat[k])
                    elif len(gt_state_cls) > 0:
                        # åªæœ‰GTæ²¡æœ‰é¢„æµ‹çš„æƒ…å†µ
                        state_stat = dict(
                            conf=torch.zeros(0, device=self.device),
                            pred_cls=torch.zeros(0, device=self.device),
                            tp=torch.zeros(0, self.niou, dtype=torch.bool, device=self.device),
                        )
                        state_stat["target_cls"] = gt_state_cls
                        state_stat["target_img"] = gt_state_cls.unique()
                        for k in self.state_det_stats.keys():
                            self.state_det_stats[k].append(state_stat[k])

            # æ”¶é›†å½“å‰å›¾åƒçš„çŠ¶æ€é¢„æµ‹å’Œç›®æ ‡ï¼ˆåŸºäºGTç»Ÿè®¡ï¼‰
            if npr > 0 and nl > 0: #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
                # ä¼ å…¥TPä¿¡æ¯ï¼Œç¡®ä¿åªç»Ÿè®¡TP
                tp_mask = stat["tp"][:, 0] if stat["tp"].numel() > 0 else torch.zeros(npr, dtype=torch.bool, device=self.device)  # ä½¿ç”¨IoU=0.5çš„TP
                self._collect_state_data_for_image(si, pred, predn, bbox, tags, matched_tags, tp_mask) #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡

            # Save
            if self.args.save_json:
                self.pred_to_json(predn, batch["im_file"][si])
            if self.args.save_txt:
                # è·å–å›¾åƒæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
                im_file_path = Path(batch["im_file"][si])
                
                # å°è¯•ä»self.dataè·å–æ•°æ®é›†æ ¹ç›®å½•
                dataset_root = None
                if hasattr(self, 'data') and self.data is not None:
                    dataset_root = self.data.get("path")
                    if dataset_root:
                        dataset_root = Path(dataset_root)
                
                # è®¡ç®—ç›¸å¯¹è·¯å¾„å¹¶æ„å»ºä¿å­˜è·¯å¾„
                if dataset_root and dataset_root.exists():
                    try:
                        # è·å–ç›¸å¯¹äºæ•°æ®é›†æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
                        relative_path = im_file_path.relative_to(dataset_root)
                        # ç§»é™¤æ–‡ä»¶åï¼Œä¿ç•™ç›®å½•ç»“æ„
                        relative_dir = relative_path.parent
                        
                        # å¦‚æœç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€éƒ¨åˆ†æ˜¯imagesï¼Œåˆ™è·³è¿‡å®ƒ
                        relative_parts = list(relative_dir.parts)
                        if relative_parts and relative_parts[0] == 'images':
                            relative_parts = relative_parts[1:]  # è·³è¿‡imagesç›®å½•
                            if relative_parts:
                                relative_dir = Path(*relative_parts)
                            else:
                                relative_dir = Path()  # ç©ºè·¯å¾„
                        
                        # æ„å»ºä¿å­˜è·¯å¾„ï¼šsave_dir/labels/ç›¸å¯¹ç›®å½•/æ–‡ä»¶å.txt
                        if relative_dir.parts:
                            save_path = self.save_dir / "labels" / relative_dir / f'{im_file_path.stem}.txt'
                        else:
                            save_path = self.save_dir / "labels" / f'{im_file_path.stem}.txt'
                    except (ValueError, AttributeError):
                        # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨è·¯å¾„å“ˆå¸ŒåŒºåˆ†
                        path_str = str(im_file_path.parent).replace(os.sep, '_').replace('/', '_')
                        # åªä¿ç•™æœ€åå‡ çº§è·¯å¾„é¿å…æ–‡ä»¶åè¿‡é•¿
                        path_parts = path_str.split('_')
                        path_suffix = '_'.join(path_parts[-3:]) if len(path_parts) > 3 else path_str[-50:]
                        save_path = self.save_dir / "labels" / f'{im_file_path.stem}_{path_suffix}.txt'
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æ•°æ®é›†æ ¹ç›®å½•ï¼Œä»å›¾åƒè·¯å¾„ä¸­æå–å­ç›®å½•ç»“æ„
                    # æŸ¥æ‰¾imagesã€trainã€valã€testç­‰å…³é”®ç›®å½•
                    path_parts = list(im_file_path.parts)
                    subdir_parts = []
                    start_idx = None
                    
                    # æ‰¾åˆ°imagesã€trainã€valã€testç­‰ç›®å½•çš„ç´¢å¼•
                    for i, part in enumerate(path_parts):
                        if part in ['images', 'train', 'val', 'test']:
                            start_idx = i + 1  # ä»è¯¥ç›®å½•ä¹‹åå¼€å§‹ï¼ˆè·³è¿‡imagesç­‰ç›®å½•ï¼‰
                            break
                    
                    if start_idx is not None and start_idx < len(path_parts) - 1:
                        # æå–å­ç›®å½•éƒ¨åˆ†ï¼ˆä¸åŒ…æ‹¬æ–‡ä»¶åï¼‰
                        subdir_parts = path_parts[start_idx:-1]
                        if subdir_parts:
                            # æ„å»ºä¿å­˜è·¯å¾„ï¼šsave_dir/labels/å­ç›®å½•/æ–‡ä»¶å.txt
                            save_path = self.save_dir / "labels" / Path(*subdir_parts) / f'{im_file_path.stem}.txt'
                        else:
                            save_path = self.save_dir / "labels" / f'{im_file_path.stem}.txt'
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°å…³é”®ç›®å½•ï¼Œä½¿ç”¨çˆ¶ç›®å½•å+æ–‡ä»¶åï¼ˆä½†è·³è¿‡imagesï¼‰
                        parent_name = im_file_path.parent.name
                        if parent_name and parent_name not in ['images', 'train', 'val', 'test']:
                            save_path = self.save_dir / "labels" / parent_name / f'{im_file_path.stem}.txt'
                        else:
                            save_path = self.save_dir / "labels" / f'{im_file_path.stem}.txt'
                
                self.save_one_txt(
                    predn,
                    self.args.save_conf,
                    pbatch["ori_shape"],
                    save_path,
                    pred=pred,  # ä¼ å…¥åŸå§‹predä»¥æå–çŠ¶æ€ä¿¡æ¯   
                )
        
        # åœ¨è°ƒç”¨reid_metricsä¹‹å‰æ£€æŸ¥batch_matched_tagsæ˜¯å¦ä¸ºç©º #%ï¿¥ï¿¥%ï¿¥#
        if batch_matched_tags and any(len(tags) > 0 for tags in batch_matched_tags): #%ï¿¥ï¿¥%ï¿¥#
            # Process batch for reid metrics
            self.reid_metrics.process_batch(preds, batch_matched_tags) #å¾€åå¤„ç†%ï¿¥ï¿¥%ï¿¥#
        
        self._process_batch_state_metrics() #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡# å¤„ç†å½“å‰æ‰¹æ¬¡çš„çŠ¶æ€é¢„æµ‹è¯„ä¼°

    def _collect_state_data_for_image(self, image_idx, pred, predn, gt_bboxes, gt_tags, matched_tags, tp_mask):
        """
        æ”¶é›†å•å¼ å›¾åƒçš„çŠ¶æ€é¢„æµ‹æ•°æ®ï¼ˆåŸºäºæ‰€æœ‰GTç»Ÿè®¡ï¼‰
        æ³¨æ„ï¼šçŠ¶æ€ç´¢å¼•ç›´æ¥ä»ç±»åˆ«ç´¢å¼•è·å–ï¼Œå› ä¸ºç±»åˆ«ç´¢å¼•0-5å¯¹åº”çŠ¶æ€ç´¢å¼•0-5
        """
        if not hasattr(self.model.model[-1], 'state_classes') or self.model.model[-1].state_classes is None:
            return
            
        embed_dim = self.model.model[-1].embed_dim
        state_classes = self.model.model[-1].state_classes
        
        # ä»é¢„æµ‹ç»“æœä¸­æå–çŠ¶æ€é¢„æµ‹
        if pred.shape[1] > 6 + embed_dim:
            state_preds = pred[:, 6+embed_dim:6+embed_dim+state_classes]  # (N_detections, state_classes)
            
            # å®‰å…¨åœ°æ£€æŸ¥å¼ é‡æ˜¯å¦ä¸ºç©ºï¼ˆå¤„ç†0ç»´å¼ é‡çš„æƒ…å†µï¼‰
            if gt_tags.numel() == 0 or len(predn) == 0:
                return
            
            # ç¡®ä¿gt_tagså’Œgt_bboxesæ˜¯æ­£ç¡®çš„ç»´åº¦
            if gt_tags.dim() == 0:
                gt_tags = gt_tags.unsqueeze(0)
            if gt_bboxes.dim() == 1:
                gt_bboxes = gt_bboxes.unsqueeze(0)
            
            
            # ç¡®ä¿tp_maskæ˜¯æ­£ç¡®çš„ç»´åº¦
            if tp_mask.dim() == 0:
                tp_mask = tp_mask.unsqueeze(0) if tp_mask.numel() > 0 else torch.zeros(len(predn), dtype=torch.bool, device=pred.device)
            if len(tp_mask) != len(predn):
                tp_mask = torch.zeros(len(predn), dtype=torch.bool, device=pred.device)
            
            # è®¡ç®—IoUçŸ©é˜µï¼Œç”¨äºæ‰¾åˆ°æ¯ä¸ªGTåŒ¹é…çš„æœ€ä½³é¢„æµ‹æ¡†
            from ultralytics.utils.metrics import box_iou
            iou_matrix = box_iou(gt_bboxes, predn[:, :4])  # (M, N)
            
            # ç›´æ¥ç»Ÿè®¡æ‰€æœ‰GTå®ä¾‹ï¼ŒçŠ¶æ€ç´¢å¼•ç›´æ¥ä»ç±»åˆ«ç´¢å¼•è·å–
            pred_states_list = []
            target_states_list = []
            
            for gt_idx, gt_tag in enumerate(gt_tags):
                gt_tag_value = gt_tag.item() if gt_tag.dim() == 0 else int(gt_tag)
                
                # å…³é”®ä¿®å¤ï¼šå‡è®¾gt_tagsæ˜¯0-basedï¼ˆ0-5ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ä½œä¸ºçŠ¶æ€ç´¢å¼•
                # å¦‚æœæ•°æ®é›†ä¸­gt_tagså®é™…ä¸Šæ˜¯1-basedï¼ˆ1-6ï¼‰ï¼Œé‚£ä¹ˆéœ€è¦å‡1
                # æ ¹æ®person_stateså­—å…¸çš„é”®æ˜¯0-basedï¼Œæˆ‘ä»¬å‡è®¾gt_tagsä¹Ÿæ˜¯0-based
                gt_state_0based = int(gt_tag_value)
                
                # æ£€æŸ¥èŒƒå›´ï¼šåº”è¯¥åœ¨0åˆ°5ä¹‹é—´ï¼ˆ0-basedï¼Œå¯¹åº”6ä¸ªçŠ¶æ€ï¼‰
                if gt_state_0based < 0 or gt_state_0based >= 6:
                    continue
                
                # æ‰¾åˆ°åŒ¹é…åˆ°è¯¥GTçš„é¢„æµ‹æ¡†ï¼ˆå¦‚æœæœ‰ï¼‰- åŒ¹é…æ—¶ä½¿ç”¨åŸå§‹çš„gt_tag_value
                matched_pred_indices = (matched_tags == gt_tag_value).nonzero(as_tuple=True)[0]
                
                if len(matched_pred_indices) > 0:
                    # ä½¿ç”¨åŒ¹é…é¢„æµ‹çš„çŠ¶æ€
                    ious = iou_matrix[gt_idx, matched_pred_indices]
                    best_pred_idx = matched_pred_indices[ious.argmax()]
                    pred_states_list.append(state_preds[best_pred_idx:best_pred_idx+1])
                else:
                    # FNæƒ…å†µï¼šä½¿ç”¨GTçŠ¶æ€ä½œä¸º"é¢„æµ‹"ï¼ˆç”¨äºç»Ÿè®¡ä¸€è‡´æ€§ï¼‰
                    # ä½¿ç”¨0-basedç´¢å¼•
                    dummy_pred = torch.zeros(1, state_classes, device=pred.device)
                    dummy_pred[0, gt_state_0based] = 1.0
                    pred_states_list.append(dummy_pred)
                
                # ä½¿ç”¨0-basedç´¢å¼•ç”¨äºStateMetrics
                target_states_list.append(torch.tensor([gt_state_0based], device=pred.device, dtype=torch.long))

            # åˆå¹¶æ‰€æœ‰GTå®ä¾‹çš„çŠ¶æ€é¢„æµ‹
            if pred_states_list and target_states_list:
                batch_pred_states = torch.cat(pred_states_list, dim=0)
                batch_target_states = torch.cat(target_states_list, dim=0)
                
                self.current_batch_pred_states.append(batch_pred_states)
                self.current_batch_target_states.append(batch_target_states)

    def _process_batch_state_metrics(self): #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
        """å¤„ç†å½“å‰æ‰¹æ¬¡çš„çŠ¶æ€é¢„æµ‹æŒ‡æ ‡"""
        if not self.current_batch_pred_states or not self.current_batch_target_states: #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            return #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            
        if self.state_metrics is None: #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            return #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            
        # åˆå¹¶å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰çŠ¶æ€é¢„æµ‹æ•°æ®
        try: #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            batch_pred_states = torch.cat(self.current_batch_pred_states, dim=0) #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            batch_target_states = torch.cat(self.current_batch_target_states, dim=0) #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            
            # æ„å»ºå›¾åƒç´¢å¼•ï¼ˆæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„å›¾åƒç´¢å¼•ï¼‰
            image_indices = []
            for img_idx, states in enumerate(self.current_batch_target_states):
                image_indices.extend([img_idx + self.seen - len(self.current_batch_target_states)] * len(states))
            image_indices = np.array(image_indices)
            
            # ç¡®ä¿ç»´åº¦åŒ¹é…
            if len(batch_pred_states) == len(batch_target_states): #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
                self.state_metrics.process(batch_pred_states, batch_target_states, image_indices) #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
                #print(f"âœ… æˆåŠŸå¤„ç† {len(batch_pred_states)} ä¸ªçŠ¶æ€é¢„æµ‹æ ·æœ¬")
                #print(f"ğŸ“ˆ å½“å‰çŠ¶æ€å‡†ç¡®ç‡: {self.state_metrics.state_accuracy:.4f}")
            else:
                print(f"è­¦å‘Šï¼šçŠ¶æ€é¢„æµ‹ç»´åº¦ä¸åŒ¹é… - pred: {len(batch_pred_states)}, target: {len(batch_target_states)}") #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
                 
        except Exception as e: #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡
            print(f"çŠ¶æ€æŒ‡æ ‡å¤„ç†é”™è¯¯: {e}") #ï¿¥#äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡

    def get_stats(self):
        """Returns metrics statistics and results dictionary."""
        stats = {k: torch.cat(v, 0).cpu().numpy() for k, v in self.stats.items()}  # to numpy
        self.nt_per_class = np.bincount(stats["target_cls"].astype(int), minlength=self.nc)
        self.nt_per_image = np.bincount(stats["target_img"].astype(int), minlength=self.nc)
        stats.pop("target_img", None)
        

        # å®šä¹‰å®Œæ•´çš„ReID metricsç»“æ„ï¼ˆæ— è®ºæ˜¯å¦æœ‰æ£€æµ‹éƒ½è¿”å›ï¼‰
        reid_metrics = {
            "val/pos_cos": 0.0,
            "val/neg_cos": 1.0,
            "val/pos_euc": 0.0,
            "val/neg_euc": 1.0,
            "val/cos_sep_ratio": 1.0,
            "val/euc_sep_ratio": 1.0,
            "val/cos_silhouette": 0.0,
            "val/euc_silhouette": 0.0,
            "val/davies_bouldin": 0.0,
            "val/calinski_harabasz": 0.0,
            "val/r1_acc": 0.0,
            "val/r5_acc": 0.0,
            "val/mean_ap": 0.0,
            "val/hota": 0.0,
            "val/mota": 0.0,
            "val/idf1": 0.0,
        }
        
        if len(stats) and stats["tp"].any():
            self.metrics.process(**stats)
            # åªæœ‰åœ¨æœ‰æ­£ç¡®æ£€æµ‹æ—¶æ‰æ›´æ–°reid_metrics
            computed_reid_metrics = self.reid_metrics.get_metrics()
            reid_metrics.update(computed_reid_metrics)  # ç”¨å®é™…è®¡ç®—å€¼è¦†ç›–é»˜è®¤å€¼
        else:
            # å½“æ²¡æœ‰æ­£ç¡®æ£€æµ‹æ—¶ï¼Œä½¿ç”¨é»˜è®¤çš„0å€¼å ä½
            print("âš ï¸ å½“å‰æ‰¹æ¬¡æ²¡æœ‰æ­£ç¡®æ£€æµ‹ï¼Œè·³è¿‡ReID metricsè®¡ç®—")
            
        detector_results = self.metrics.results_dict
        detector_results.update(reid_metrics)
        
        # ========== ä¿®å¤ï¼šç¡®ä¿çŠ¶æ€é¢„æµ‹æŒ‡æ ‡å§‹ç»ˆè¿”å›11ä¸ªé”® ==========
        # å®šä¹‰å®Œæ•´çš„çŠ¶æ€é¢„æµ‹æŒ‡æ ‡ç»“æ„ï¼ˆä¸StateMetrics.results_dictè¿”å›çš„é”®å®Œå…¨ä¸€è‡´ï¼‰
        default_state_metrics = {
            "metrics/state_accuracy": 0.0,
            "metrics/state_macro_accuracy": 0.0,
            "metrics/state_macro_precision": 0.0,
            "metrics/state_macro_recall": 0.0,
            "metrics/state_macro_f1": 0.0,
            "metrics/state_micro_precision": 0.0,
            "metrics/state_micro_recall": 0.0,
            "metrics/state_micro_f1": 0.0,
            "metrics/state_total_tp": 0,
            "metrics/state_total_fp": 0,
            "metrics/state_total_fn": 0,
        }
        
        if self.state_metrics is not None:
            state_results = self.state_metrics.results_dict
            # ç”¨å®é™…è®¡ç®—å€¼æ›´æ–°é»˜è®¤å€¼ï¼ˆç¡®ä¿é”®å®Œå…¨åŒ¹é…ï¼‰
            default_state_metrics.update(state_results)
        
        # æ— è®ºæ˜¯å¦æœ‰state_metricsï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„é”®ç»“æ„
        detector_results.update(default_state_metrics)

        # ========== ä¿®å¤ï¼šç¡®ä¿çŠ¶æ€æ£€æµ‹æŒ‡æ ‡å§‹ç»ˆè¿”å›6ä¸ªé”® ==========
        # å®šä¹‰å®Œæ•´çš„çŠ¶æ€æ£€æµ‹æŒ‡æ ‡ç»“æ„ï¼ˆä¸DetMetrics.results_dictè¿”å›çš„é”®å®Œå…¨ä¸€è‡´ï¼‰
        default_state_det_metrics = {
            "state_det/metrics/precision(B)": 0.0,
            "state_det/metrics/recall(B)": 0.0,
            "state_det/metrics/mAP50(B)": 0.0,
            "state_det/metrics/mAP75(B)": 0.0,
            "state_det/metrics/mAP50-95(B)": 0.0,
            "state_det/fitness": 0.0,
        }
        
        if hasattr(self, "state_det_stats") and len(self.state_det_stats) > 0:
            state_det_stats = {k: torch.cat(v, 0).cpu().numpy() if v else np.array([]) 
                          for k, v in self.state_det_stats.items()}
            
            if len(state_det_stats) > 0 and state_det_stats["tp"].size > 0 and state_det_stats["tp"].any():
                # ä¸´æ—¶ä¿å­˜åŸå§‹ncå’Œnt_per_class
                original_nc = self.nc
                original_nt_per_class = self.nt_per_class
                
                # è®¾ç½®çŠ¶æ€ç±»åˆ«æ•°
                state_classes = getattr(self.model.model[-1], "state_classes", 6) if hasattr(self, "model") and self.model is not None else 6
                self.nc = state_classes
                
                # è®¡ç®—çŠ¶æ€æ£€æµ‹çš„æ¯ç±»ç»Ÿè®¡ä¿¡æ¯ï¼ˆåœ¨pop target_imgä¹‹å‰ï¼‰
                self.state_nt_per_class = np.bincount(
                    state_det_stats["target_cls"].astype(int), 
                    minlength=state_classes
                )
                # è®¡ç®—æ¯ç±»å‡ºç°çš„å›¾åƒæ•°
                if "target_img" in state_det_stats and state_det_stats["target_img"].size > 0:
                    self.state_nt_per_image = np.bincount(
                        state_det_stats["target_img"].astype(int), 
                        minlength=state_classes
                    )
                else:
                    self.state_nt_per_image = np.zeros(state_classes, dtype=np.int64)
                
                state_det_stats.pop("target_img", None)
                
                # ä½¿ç”¨DetMetricsè®¡ç®—çŠ¶æ€æ£€æµ‹æŒ‡æ ‡
                self.state_det_metrics.process(**state_det_stats)
                state_det_results = self.state_det_metrics.results_dict
                
                # æ¢å¤åŸå§‹nc
                self.nc = original_nc
                self.nt_per_class = original_nt_per_class
                
                # é‡å‘½åçŠ¶æ€æ£€æµ‹æŒ‡æ ‡ï¼ˆæ·»åŠ å‰ç¼€ï¼‰
                state_det_results_renamed = {
                    f"state_det/{k}": v for k, v in state_det_results.items()
                }
                # ç”¨å®é™…è®¡ç®—å€¼æ›´æ–°é»˜è®¤å€¼ï¼ˆç¡®ä¿é”®å®Œå…¨åŒ¹é…ï¼‰
                default_state_det_metrics.update(state_det_results_renamed)
        
            # åˆå§‹åŒ–ç©ºçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not hasattr(self, 'state_nt_per_class'):
                state_classes = getattr(self.model.model[-1], "state_classes", 6) if hasattr(self, "model") and self.model is not None else 6
                self.state_nt_per_class = np.zeros(state_classes, dtype=np.int64)
                self.state_nt_per_image = np.zeros(state_classes, dtype=np.int64)
        
        # æ— è®ºæ˜¯å¦æœ‰state_det_statsï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„é”®ç»“æ„
        detector_results.update(default_state_det_metrics)
        
        return detector_results

    def preprocess(self, batch):
        """Preprocesses batch by converting masks to float and sending to device."""
        batch = super().preprocess(batch)
        batch["tags"] = batch["tags"].to(self.device).float()
        return batch

    def postprocess(self, preds):
        """Apply Non-maximum suppression to prediction outputs."""
        
        
        # åº”ç”¨NMSï¼ˆåªå¯¹æ£€æµ‹éƒ¨åˆ†ï¼‰
        preds = ops.non_max_suppression(
            preds[0],
            self.args.conf,
            self.args.iou,
            labels=self.lb,
            multi_label=True,
            agnostic=self.args.single_cls or self.args.agnostic_nms,
            max_det=self.args.max_det,
            nc=self.nc,
        )
        return preds

    def _process_batch(self, detections, gt_bboxes, gt_cls, gt_tags):
        """
        Return correct prediction matrix.

        Args:
            detections (torch.Tensor): Tensor of shape (N, 6) representing detections where each detection is
                (x1, y1, x2, y2, conf, class).
            gt_bboxes (torch.Tensor): Tensor of shape (M, 4) representing ground-truth bounding box coordinates. Each
                bounding box is of the format: (x1, y1, x2, y2).
            gt_cls (torch.Tensor): Tensor of shape (M,) representing target class indices.
            gt_tags (torch.Tensor): Tensor of shape (M,) representing target tags.

        Returns:
            (torch.Tensor): Correct prediction matrix of shape (N, 10) for 10 IoU levels.

        Note:
            The function does not return any value directly usable for metrics calculation. Instead, it provides an
            intermediate representation used for evaluating predictions against ground truth.
        """
        iou = box_iou(gt_bboxes, detections[:, :4])
        return self.match_predictions(detections[:, 5], gt_cls, gt_tags, iou)

    def match_predictions(self, pred_classes, true_classes, true_tags, iou, use_scipy=False):
        """
        Matches predictions to ground truth objects (pred_classes, true_classes) using IoU.

        Args:
            pred_classes (torch.Tensor): Predicted class indices of shape(N,).
            true_classes (torch.Tensor): Target class indices of shape(M,).
            true_tags (torch.Tensor): Target tags of shape(M,).
            iou (torch.Tensor): An NxM tensor containing the pairwise IoU values for predictions and ground of truth
            use_scipy (bool): Whether to use scipy for matching (more precise).

        Returns:
            (torch.Tensor): Correct tensor of shape(N,10) for 10 IoU thresholds.
        """
        # Initialize the list for storing matched tags using IoU threshold of 0.5
        matched_tags = [False] * pred_classes.shape[0]  # Default to None if no match

        # Dx10 matrix, where D - detections, 10 - IoU thresholds
        correct = np.zeros((pred_classes.shape[0], self.iouv.shape[0])).astype(bool)
        # LxD matrix where L - labels (rows), D - detections (columns)
        correct_class = true_classes[:, None] == pred_classes
        iou = iou * correct_class  # zero out the wrong classes
        iou = iou.cpu().numpy()
        for i, threshold in enumerate(self.iouv.cpu().tolist()):
            if use_scipy:
                # WARNING: known issue that reduces mAP in https://github.com/ultralytics/ultralytics/pull/4708
                import scipy  # scope import to avoid importing for all commands

                cost_matrix = iou * (iou >= threshold)
                if cost_matrix.any():
                    labels_idx, detections_idx = scipy.optimize.linear_sum_assignment(cost_matrix, maximize=True)
                    valid = cost_matrix[labels_idx, detections_idx] > 0
                    if valid.any():
                        correct[detections_idx[valid], i] = True
                        # Assign tags to matched predictions
                        if threshold == self.state_iou:  #ï¿¥#ï¿¥#ï¿¥#ï¿¥#ï¿¥#ï¿¥#
                            for gt_idx, pred_idx in zip(labels_idx[valid], detections_idx[valid]):
                                matched_tags[pred_idx] = true_tags[gt_idx].item()
            else:
                matches = np.nonzero(iou >= threshold)  # IoU > threshold and classes match
                matches = np.array(matches).T
                if matches.shape[0]:
                    if matches.shape[0] > 1:
                        matches = matches[iou[matches[:, 0], matches[:, 1]].argsort()[::-1]]
                        matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                        # matches = matches[matches[:, 2].argsort()[::-1]]
                        matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
                    correct[matches[:, 1].astype(int), i] = True
                    # Assign tags to matched predictions
                    if threshold == self.state_iou:  #ï¿¥#ï¿¥#ï¿¥#ï¿¥#ï¿¥#ï¿¥#
                        for gt_idx, pred_idx in matches:
                            if true_tags.dim() > 0: #$#$#
                                matched_tags[pred_idx] = true_tags[gt_idx].item()
        return torch.tensor(correct, dtype=torch.bool, device=pred_classes.device), torch.tensor(matched_tags, dtype=torch.int, device=pred_classes.device)

    def match_predictions_for_state_detection(self, pred_classes, true_classes, iou, use_scipy=False):
        """
        ä¸“é—¨ç”¨äºçŠ¶æ€æ£€æµ‹çš„åŒ¹é…å‡½æ•°ï¼šå…ˆåŒ¹é…æ¡†ï¼ˆåŸºäºIoUï¼‰ï¼Œå†åˆ¤æ–­çŠ¶æ€ç±»åˆ«æ˜¯å¦æ­£ç¡®
        
        ä¸match_predictionsçš„åŒºåˆ«ï¼š
        - match_predictions: å…ˆæ£€æŸ¥ç±»åˆ«åŒ¹é…ï¼Œå†åŒ¹é…æ¡†ï¼ˆç”¨äºå¸¸è§„æ£€æµ‹ï¼‰
        - match_predictions_for_state_detection: å…ˆåŒ¹é…æ¡†ï¼Œå†æ£€æŸ¥çŠ¶æ€ç±»åˆ«ï¼ˆç”¨äºçŠ¶æ€æ£€æµ‹ï¼‰
        
        Args:
            pred_classes (torch.Tensor): é¢„æµ‹çš„çŠ¶æ€ç±»åˆ« (N,)
            true_classes (torch.Tensor): çœŸå®çš„çŠ¶æ€ç±»åˆ« (M,)
            iou (torch.Tensor): IoUçŸ©é˜µ (M, N)ï¼ŒMæ˜¯GTæ•°é‡ï¼ŒNæ˜¯é¢„æµ‹æ•°é‡
            use_scipy (bool): æ˜¯å¦ä½¿ç”¨scipyè¿›è¡ŒåŒ¹é…ï¼ˆæ›´ç²¾ç¡®ï¼‰
        
        Returns:
            (torch.Tensor): TPçŸ©é˜µ (N, 10) å¯¹äº10ä¸ªIoUé˜ˆå€¼ï¼Œdtype=bool
        """
        # Dx10 matrix, where D - detections, 10 - IoU thresholds
        correct = np.zeros((pred_classes.shape[0], self.iouv.shape[0])).astype(bool)
        iou_np = iou.cpu().numpy()  # è½¬æ¢ä¸ºnumpyç”¨äºè®¡ç®—
        
        for i, threshold in enumerate(self.iouv.cpu().tolist()):
            if use_scipy:
                # WARNING: known issue that reduces mAP in https://github.com/ultralytics/ultralytics/pull/4708
                import scipy.optimize  # scope import to avoid importing for all commands
                
                # å…ˆåŸºäºIoUåŒ¹é…æ¡†ï¼ˆä¸è€ƒè™‘ç±»åˆ«ï¼‰
                cost_matrix = iou_np * (iou_np >= threshold)
                if cost_matrix.any():
                    labels_idx, detections_idx = scipy.optimize.linear_sum_assignment(
                        cost_matrix, maximize=True
                    )
                    valid = cost_matrix[labels_idx, detections_idx] > 0
                    if valid.any():
                        # åŒ¹é…åˆ°æ¡†åï¼Œå†æ£€æŸ¥çŠ¶æ€ç±»åˆ«æ˜¯å¦åŒ¹é…
                        for gt_idx, pred_idx in zip(labels_idx[valid], detections_idx[valid]):
                            if true_classes[gt_idx].item() == pred_classes[pred_idx].item():
                                correct[pred_idx, i] = True
            else:
                # å…ˆæ‰¾åˆ°æ‰€æœ‰IoU >= thresholdçš„åŒ¹é…ï¼ˆä¸è€ƒè™‘ç±»åˆ«ï¼‰
                matches = np.nonzero(iou_np >= threshold)  # IoU >= threshold
                matches = np.array(matches).T  # (num_matches, 2)ï¼Œæ¯è¡Œæ˜¯[gt_idx, pred_idx]
                if matches.shape[0]:
                    if matches.shape[0] > 1:
                        # æŒ‰IoUé™åºæ’åº
                        matches = matches[iou_np[matches[:, 0], matches[:, 1]].argsort()[::-1]]
                        # æ¯ä¸ªé¢„æµ‹æ¡†åªä¿ç•™IoUæœ€é«˜çš„GTï¼ˆå»é‡é¢„æµ‹æ¡†ï¼‰
                        matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                        # æ¯ä¸ªGTåªä¿ç•™IoUæœ€é«˜çš„é¢„æµ‹æ¡†ï¼ˆå»é‡GTï¼‰
                        matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
                    
                    # æ£€æŸ¥åŒ¹é…çš„æ¡†çš„çŠ¶æ€ç±»åˆ«æ˜¯å¦ä¹ŸåŒ¹é…
                    for gt_idx, pred_idx in matches:
                        if true_classes[gt_idx].item() == pred_classes[pred_idx].item():
                            correct[pred_idx, i] = True
        
        return torch.tensor(correct, dtype=torch.bool, device=pred_classes.device)

    def print_results(self): #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡çš„æ‰“å°
        """Prints training/validation set metrics per class and state metrics."""
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•æ˜¾ç¤ºæ£€æµ‹æŒ‡æ ‡
        super().print_results() #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡çš„æ‰“å°
        
        # æ˜¾ç¤ºçŠ¶æ€é¢„æµ‹æŒ‡æ ‡
        if self.state_metrics is not None and self.state_metrics.total > 0: #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡çš„æ‰“å°
            # æ›´æ–°æ ¼å¼åŒ–æŒ‡æ ‡
            self.state_metrics.update_formatted_metrics()
            
            # è®¡ç®—æ¯ä¸ªçŠ¶æ€å‡ºç°åœ¨å¤šå°‘å¼ å›¾åƒä¸­
            state_image_counts = np.array([len(s) for s in self.state_metrics.state_images_set])
            
            # æ ¼å¼åŒ–è¾“å‡ºï¼Œç±»ä¼¼æ£€æµ‹æŒ‡æ ‡
            pf = "%22s" + "%11i" * 2 + "%11.3g" * 5  # print format: Class + Images + Instances + 5ä¸ªæŒ‡æ ‡
            pf2 = "%22s" + "%11s" * 2 + "%11.3s" * 5
            
            # æ‰“å°æ¯ä¸ªçŠ¶æ€ç±»åˆ«çš„è¯¦ç»†ç»Ÿè®¡
            if self.args.verbose and not self.training:
                # å°è¯•è·å–çŠ¶æ€åç§°æ˜ å°„
                state_names = {}
                num_defined_states = 6  # é»˜è®¤6ä¸ªçŠ¶æ€
                if hasattr(self, 'model') and hasattr(self.model, 'person_states') and isinstance(self.model.person_states, dict):
                    for k, v in self.model.person_states.items():
                        if isinstance(k, int):
                            state_names[k] = str(v)
                            num_defined_states = max(num_defined_states, k + 1)
                        elif isinstance(v, int):
                            state_names[v] = str(k)
                            num_defined_states = max(num_defined_states, v + 1)
                
                # æŒ‰ç…§çŠ¶æ€ç´¢å¼•é¡ºåºï¼ˆ0åˆ°num_defined_states-1ï¼‰æ‰“å°æ‰€æœ‰çŠ¶æ€
                for state_idx in range(num_defined_states):
                    state_name = state_names.get(state_idx, f"State_{state_idx}")
                    images_count = int(state_image_counts[state_idx]) if state_idx < len(state_image_counts) else 0
                    instances_count = int(self.state_metrics.state_total_counts[state_idx]) if state_idx < len(self.state_metrics.state_total_counts) else 0
                    
                    # ä½¿ç”¨state_resultæ–¹æ³•æ ¹æ®çŠ¶æ€ç´¢å¼•è·å–æŒ‡æ ‡
                    metrics = self.state_metrics.state_result(state_idx)
                    
                    LOGGER.info(
                        pf % (state_name, images_count, instances_count, *metrics)
                    )
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%            
            # ========== ä»¥ä¸‹ä¸ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯è¾“å‡ºï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸æ‰“å° ==========
            # è·å– TPã€FPã€FN
            tp, fp, fn = self.state_metrics.get_tp_fp_fn()
            precision, recall, f1 = self.state_metrics.get_precision_recall_f1()
            
            # æ€»ä½“ç»Ÿè®¡
            total_tp = int(tp.sum())
            total_fp = int(fp.sum())
            total_fn = int(fn.sum())
            
            print(
                f"âœ…State Prediction Results (IoU={self.state_iou}): ğŸ”„Total samples: {self.state_metrics.total}, "
                f"ğŸ“ˆAccuracy: {self.state_metrics.state_accuracy:.4f}, "
                f"ğŸ“ŠMacro Accuracy: {self.state_metrics.per_state_accuracy.mean():.4f}"
            )
                       
        else:    #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡çš„æ‰“å°
            LOGGER.info("No state prediction data available for evaluation") #ï¿¥#æ·»åŠ äººå‘˜çŠ¶æ€é¢„æµ‹è¯„ä¼°æŒ‡æ ‡çš„æ‰“å°

        # ========== åœ¨æ–¹æ³•æœ«å°¾æ·»åŠ ä¿å­˜Excelçš„é€»è¾‘ ==========
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨Excelä¿å­˜åŠŸèƒ½ï¼ˆä½¿ç”¨å®ä¾‹å˜é‡ï¼‰
        save_excel = getattr(self, '_save_excel', False)
        if save_excel and not self.training:
            LOGGER.info(f"âœ… å¼€å§‹ä¿å­˜è¯„ä¼°ç»“æœåˆ°Excel (save_excel={save_excel})")
            self._save_results_to_excel()

    def save_one_txt(self, predn, save_conf, shape, file, pred=None):
        """
        Save YOLO detections to a txt file in normalized coordinates.
        If save_tag_to_txt is True, adds state information as the last column.
        
        Args:
            predn: NMSåçš„é¢„æµ‹ç»“æœï¼Œæ ¼å¼ä¸º [x1, y1, x2, y2, conf, cls]
            save_conf: æ˜¯å¦ä¿å­˜ç½®ä¿¡åº¦
            shape: å›¾åƒå½¢çŠ¶
            file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            pred: NMSå‰çš„åŸå§‹é¢„æµ‹ç»“æœï¼ˆå¯é€‰ï¼Œç”¨äºæå–çŠ¶æ€ä¿¡æ¯ï¼‰
        """
        from ultralytics.engine.results import Results
        from ultralytics.utils.metrics import box_iou
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜çŠ¶æ€ä¿¡æ¯
        save_tag_to_txt = getattr(self, '_save_tag_to_txt', False)
        
        # æå–çŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ä¸”predæä¾›ä¸”æ¨¡å‹æ”¯æŒçŠ¶æ€é¢„æµ‹ï¼‰
        state_cls_list = None
        if save_tag_to_txt and pred is not None:
            if hasattr(self.model.model[-1], "state_classes") and self.model.model[-1].state_classes is not None:
                embed_dim = self.model.model[-1].embed_dim
                state_classes = self.model.model[-1].state_classes
                
                # æ£€æŸ¥predæ˜¯å¦åŒ…å«çŠ¶æ€ä¿¡æ¯
                if pred.shape[1] > 6 + embed_dim and len(predn) > 0 and len(pred) > 0:
                    # ä»predä¸­æå–çŠ¶æ€é¢„æµ‹
                    state_probs_raw = pred[:, 6 + embed_dim:6 + embed_dim + state_classes]  # (N_pred, state_classes)
                    
                    # å¯¹çŠ¶æ€æ¦‚ç‡è¿›è¡Œsoftmax
                    state_probs_raw = torch.softmax(state_probs_raw, dim=1)
                    
                    # æ‰¾åˆ°prednä¸­æ¯ä¸ªé¢„æµ‹æ¡†å¯¹åº”çš„predä¸­çš„ç´¢å¼•ï¼ˆé€šè¿‡bbox IoUåŒ¹é…ï¼‰
                    pred_bboxes = pred[:, :4]  # (N_pred, 4)
                    predn_bboxes = predn[:, :4]  # (N_predn, 4)
                    
                    # è®¡ç®—IoUçŸ©é˜µ
                    iou_matrix = box_iou(predn_bboxes, pred_bboxes)  # (N_predn, N_pred)
                    
                    # ä¸ºæ¯ä¸ªprednæ‰¾åˆ°æœ€åŒ¹é…çš„predç´¢å¼•
                    matched_indices = iou_matrix.argmax(dim=1)  # (N_predn,)
                    
                    # ä»åŒ¹é…çš„predä¸­æå–çŠ¶æ€é¢„æµ‹
                    state_probs = state_probs_raw[matched_indices]  # (N_predn, state_classes)
                    
                    # è·å–çŠ¶æ€ç±»åˆ«ï¼ˆæœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»åˆ«ï¼‰
                    _, state_cls = state_probs.max(1)  # (N_predn,)
                    state_cls_list = state_cls.cpu().numpy().tolist()
        
        # å¦‚æœæå–åˆ°äº†çŠ¶æ€ä¿¡æ¯ï¼Œæ‰‹åŠ¨å†™å…¥æ–‡ä»¶
        if state_cls_list is not None:
            Path(file).parent.mkdir(parents=True, exist_ok=True)
            with open(file, "a") as f:
                # åˆ›å»ºResultså¯¹è±¡ç”¨äºè·å–å½’ä¸€åŒ–åæ ‡
                results = Results(
                    np.zeros((shape[0], shape[1]), dtype=np.uint8),
                    path=None,
                    names=self.names,
                    boxes=predn[:, :6],
                )
                
                for i, box in enumerate(results.boxes):
                    c = int(box.cls)
                    conf = float(box.conf)
                    # è½¬æ¢ä¸ºå½’ä¸€åŒ–çš„xywhæ ¼å¼
                    xywhn = box.xywhn[0].cpu().numpy()
                    
                    # æ„å»ºè¾“å‡ºè¡Œï¼šclass x_center y_center width height [conf] state
                    line = [c, xywhn[0], xywhn[1], xywhn[2], xywhn[3]]
                    if save_conf:
                        line.append(conf)
                    # æ·»åŠ çŠ¶æ€ç±»åˆ« - ç¡®ä¿æ¯ä¸ªæ¡†éƒ½ä½¿ç”¨æ­£ç¡®çš„çŠ¶æ€ç±»åˆ«
                    state_cls_val = state_cls_list[i] if i < len(state_cls_list) else 0
                    line.append(state_cls_val)
                    
                    # å†™å…¥æ–‡ä»¶
                    f.write(("%g " * len(line)).rstrip() % tuple(line) + "\n")
        else:
            # å¦‚æœæ²¡æœ‰çŠ¶æ€ä¿¡æ¯ï¼Œä½¿ç”¨çˆ¶ç±»çš„é»˜è®¤ä¿å­˜æ–¹å¼
            super().save_one_txt(predn, save_conf, shape, file)

    def _save_results_to_excel(self):
        """ä¿å­˜è¯„ä¼°ç»“æœåˆ°Excelæ–‡ä»¶"""
        # å…ˆå°è¯•å¯¼å…¥å¿…è¦çš„åº“
        try:
            import pandas as pd
        except ImportError as e:
            LOGGER.warning(f"âš ï¸ æ— æ³•å¯¼å…¥pandas: {e}")
            LOGGER.warning(f"âš ï¸ è¯·å®‰è£…pandas: pip install pandas")
            return
        
        try:
            import openpyxl
        except ImportError as e:
            LOGGER.warning(f"âš ï¸ æ— æ³•å¯¼å…¥openpyxl: {e}")
            LOGGER.warning(f"âš ï¸ è¯·å®‰è£…openpyxl: pip install openpyxl")
            return
        
        try:
            from pathlib import Path
            
            # è·å–æ¨¡å‹åç§°ï¼ˆä½¿ç”¨å®ä¾‹å˜é‡ï¼‰
            model_name = getattr(self, '_model_name', 'unknown')
            
            # è·å–Excelä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨å®ä¾‹å˜é‡ï¼‰
            excel_save_dir = getattr(self, '_excel_save_dir', None)
            excel_name = getattr(self, '_excel_name', 'result_all.xlsx')
            if excel_save_dir:
                excel_path = Path(excel_save_dir) / excel_name
            else:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨é¡¹ç›®ç›®å½•çš„çˆ¶ç›®å½•
                excel_path = Path(self.save_dir).parent / excel_name
            
            LOGGER.info(f"ğŸ“ Excelæ–‡ä»¶è·¯å¾„: {excel_path}")
            
            # å‡†å¤‡æ•°æ®å­—å…¸
            row_data = {}
            
            # ç¬¬1åˆ—ï¼šæ¨¡å‹åç§°
            row_data['Model'] = model_name
            
            # ç¬¬2-8åˆ—ï¼šæ£€æµ‹æŒ‡æ ‡ (Images, Instances, P, R, mAP50, mAP75, mAP50-95)
            det_results = self.metrics.mean_results()  # [P, R, mAP50, mAP75, mAP50-95]
            row_data['Images'] = self.seen
            row_data['Instances'] = int(self.nt_per_class.sum())
            row_data['Box_P'] = round(float(det_results[0]), 3) if len(det_results) > 0 else 0.0
            row_data['Box_R'] = round(float(det_results[1]), 3) if len(det_results) > 1 else 0.0
            row_data['Box_mAP50'] = round(float(det_results[2]), 3) if len(det_results) > 2 else 0.0
            row_data['Box_mAP75'] = round(float(det_results[3]), 3) if len(det_results) > 3 else 0.0
            row_data['Box_mAP50-95'] = round(float(det_results[4]), 3) if len(det_results) > 4 else 0.0
            
            # ç¬¬9-10åˆ—ï¼šState Prediction Results (Accuracy, Macro Accuracy)
            if self.state_metrics is not None and self.state_metrics.total > 0:
                row_data['State_Accuracy'] = round(float(self.state_metrics.state_accuracy), 4)
                support = self.state_metrics.state_total_counts > 0
                row_data['State_Macro_Accuracy'] = round(float(self.state_metrics.per_state_accuracy[support].mean()), 4) if support.any() else 0.0
            else:
                row_data['State_Accuracy'] = 0.0
                row_data['State_Macro_Accuracy'] = 0.0
            
            # ç¬¬11-13åˆ—ï¼šState Prediction Metrics (P, R, F1)
            if self.state_metrics is not None and self.state_metrics.total > 0:
                self.state_metrics.update_formatted_metrics()
                state_pred_results = self.state_metrics.mean_results()  # [mp, mr, mf1, 0, 0]
                row_data['State_Pred_P'] = round(float(state_pred_results[0]), 3) if len(state_pred_results) > 0 else 0.0
                row_data['State_Pred_R'] = round(float(state_pred_results[1]), 3) if len(state_pred_results) > 1 else 0.0
                row_data['State_Pred_F1'] = round(float(state_pred_results[2]), 3) if len(state_pred_results) > 2 else 0.0
            else:
                row_data['State_Pred_P'] = 0.0
                row_data['State_Pred_R'] = 0.0
                row_data['State_Pred_F1'] = 0.0
            
            # ç¬¬14-18åˆ—ï¼šState Detection Metrics (pre, rec, mAP50, mAP75, mAP50-95)
            if hasattr(self, "state_det_metrics") and hasattr(self, "state_det_stats") and len(self.state_det_stats) > 0:
                state_det_stats = {k: torch.cat(v, 0).cpu().numpy() if v else np.array([]) 
                                      for k, v in self.state_det_stats.items()}
                if len(state_det_stats) > 0 and state_det_stats["tp"].size > 0 and state_det_stats["tp"].any():
                    state_det_stats.pop("target_img", None)
                    self.state_det_metrics.process(**state_det_stats)
                    state_det_results = self.state_det_metrics.mean_results()  # [P, R, mAP50, mAP75, mAP50-95]
                    row_data['State_Det_P'] = round(float(state_det_results[0]), 3) if len(state_det_results) > 0 else 0.0
                    row_data['State_Det_R'] = round(float(state_det_results[1]), 3) if len(state_det_results) > 1 else 0.0
                    row_data['State_Det_mAP50'] = round(float(state_det_results[2]), 3) if len(state_det_results) > 2 else 0.0
                    row_data['State_Det_mAP75'] = round(float(state_det_results[3]), 3) if len(state_det_results) > 3 else 0.0
                    row_data['State_Det_mAP50-95'] = round(float(state_det_results[4]), 3) if len(state_det_results) > 4 else 0.0
                else:
                    row_data['State_Det_P'] = 0.0
                    row_data['State_Det_R'] = 0.0
                    row_data['State_Det_mAP50'] = 0.0
                    row_data['State_Det_mAP75'] = 0.0
                    row_data['State_Det_mAP50-95'] = 0.0
            else:
                row_data['State_Det_P'] = 0.0
                row_data['State_Det_R'] = 0.0
                row_data['State_Det_mAP50'] = 0.0
                row_data['State_Det_mAP75'] = 0.0
                row_data['State_Det_mAP50-95'] = 0.0
            
            # è¯»å–æˆ–åˆ›å»ºExcelæ–‡ä»¶
            if excel_path.exists():
                try:
                    # è¯»å–ç°æœ‰Excelæ–‡ä»¶
                    df = pd.read_excel(excel_path, sheet_name=0, engine='openpyxl')
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æ¨¡å‹åç§°çš„è¡Œ
                    if 'Model' in df.columns:
                        model_idx = df[df['Model'] == model_name].index
                        if len(model_idx) > 0:
                            # æ›´æ–°ç°æœ‰è¡Œ
                            for col, val in row_data.items():
                                df.at[model_idx[0], col] = val
                            LOGGER.info(f"ğŸ“ æ›´æ–°Excelä¸­æ¨¡å‹ '{model_name}' çš„æ•°æ®")
                        else:
                            # æ·»åŠ æ–°è¡Œ
                            df = pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)
                            LOGGER.info(f"ğŸ“ åœ¨Excelä¸­æ·»åŠ æ–°æ¨¡å‹ '{model_name}' çš„æ•°æ®")
                    else:
                        # å¦‚æœModelåˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ æ–°è¡Œ
                        df = pd.concat([df, pd.DataFrame([row_data])], ignore_index=True)
                        LOGGER.info(f"ğŸ“ Excelæ–‡ä»¶ç¼ºå°‘Modelåˆ—ï¼Œæ·»åŠ æ–°è¡Œ")
                except Exception as e:
                    LOGGER.warning(f"âš ï¸ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    # å¦‚æœè¯»å–å¤±è´¥ï¼Œåˆ›å»ºæ–°çš„DataFrame
                    df = pd.DataFrame([row_data])
                    LOGGER.info(f"ğŸ“ åˆ›å»ºæ–°çš„Excelæ–‡ä»¶")
            else:
                # åˆ›å»ºæ–°çš„DataFrame
                df = pd.DataFrame([row_data])
                LOGGER.info(f"ğŸ“ åˆ›å»ºæ–°çš„Excelæ–‡ä»¶")
            
            # ä¿å­˜åˆ°Excel
            df.to_excel(excel_path, index=False, engine='openpyxl')
            LOGGER.info(f"âœ… è¯„ä¼°ç»“æœå·²æˆåŠŸä¿å­˜åˆ°Excel: {excel_path}")
            
        except ImportError as e:
            LOGGER.warning(f"âš ï¸ å¯¼å…¥åº“æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        except Exception as e:
            LOGGER.warning(f"âš ï¸ ä¿å­˜Excelæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
